{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch.backends.cudnn as cudnn\n",
    "import random\n",
    "import numpy as np\n",
    "import logging\n",
    "import sys \n",
    "\n",
    "# For path issues try to add the appropriate path using sys.path.append \n",
    "\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset.data_loader import VGDataset\n",
    "from utils.utils import adjust_learning_rate\n",
    "from utils.checkpoint import save_checkpoint\n",
    "from todo import VGModel, train_epoch, validate_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the data_root and split_root paths accroding to your directory and the respective dataset location. \n",
    "#Try to change the checkpoint store path to google drive. \n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.data_root = \"./data\"\n",
    "        self.gpu = 0\n",
    "        self.workers = 2\n",
    "        self.nb_epoch = 3\n",
    "        self.lr = 5e-5\n",
    "        self.lr_dev = 0.1\n",
    "        self.batch_size = 12\n",
    "        self.size = 640\n",
    "        self.split_root = \"data\"\n",
    "        self.dataset = \"gref\"\n",
    "        self.time = 40\n",
    "        self.print_freq = 50\n",
    "        self.savename = \"ckpt\"\n",
    "        self.seed = 0\n",
    "        self.bert_model = \"bert-base-uncased\"\n",
    "        self.test = False\n",
    "        self.w_div = 0.125\n",
    "        self.tunebert = True\n",
    "        self.device = \"cuda\"\n",
    "        self.no_aux_loss = False\n",
    "        self.backbone = \"resnet50\"\n",
    "        self.position_embedding = \"sine\"\n",
    "        self.enc_layers = 6\n",
    "        self.dec_layers = 6\n",
    "        self.dim_feedforward = 2048\n",
    "        self.hidden_dim = 256\n",
    "        self.dropout = 0.1\n",
    "        self.nheads = 8\n",
    "        self.num_queries = 441\n",
    "        self.masks = False\n",
    "        self.dilation = False\n",
    "        self.pre_norm = False\n",
    "args = Args()\n",
    "\n",
    "# Env settings\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu)\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed+1)\n",
    "torch.manual_seed(args.seed+2)\n",
    "torch.cuda.manual_seed_all(args.seed+3)\n",
    "\n",
    "# Log settings\n",
    "if not os.path.exists('./logs'):\n",
    "    os.mkdir('logs')\n",
    "logging.basicConfig(level=logging.INFO, filename=\"./logs/%s\"%args.savename, filemode=\"a+\",\n",
    "                    format=\"%(asctime)-15s %(levelname)-8s %(message)s\")\n",
    "logging.info(str(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build data loaders\n",
    "input_transform = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    )\n",
    "])\n",
    "\n",
    "# Dataset\n",
    "train_dataset = VGDataset(data_root=args.data_root,\n",
    "                        split_root=args.split_root,\n",
    "                        dataset=args.dataset,\n",
    "                        split='train',\n",
    "                        imsize = args.size,\n",
    "                        transform=input_transform,\n",
    "                        max_query_len=args.time,\n",
    "                        augment=True)\n",
    "val_dataset = VGDataset(data_root=args.data_root,\n",
    "                        split_root=args.split_root,\n",
    "                        dataset=args.dataset,\n",
    "                        split='val',\n",
    "                        imsize = args.size,\n",
    "                        transform=input_transform,\n",
    "                        max_query_len=args.time)\n",
    "test_dataset = VGDataset(data_root=args.data_root,\n",
    "                        split_root=args.split_root,\n",
    "                        dataset=args.dataset,\n",
    "                        testmode=True,\n",
    "                        split='val',\n",
    "                        imsize = args.size,\n",
    "                        transform=input_transform,\n",
    "                        max_query_len=args.time)\n",
    "train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True,\n",
    "                        pin_memory=True, drop_last=True, num_workers=args.workers)\n",
    "val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False,\n",
    "                        pin_memory=True, drop_last=True, num_workers=args.workers)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False,\n",
    "                        pin_memory=True, drop_last=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "model = VGModel(\n",
    "    bert_model=args.bert_model,\n",
    "    tunebert=args.tunebert, \n",
    "    args=args,\n",
    ")\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "\n",
    "print('Num of parameters:', sum([param.nelement() for param in model.parameters()]))\n",
    "logging.info('Num of parameters:%d'%int(sum([param.nelement() for param in model.parameters()])))\n",
    "\n",
    "if args.tunebert:\n",
    "    visu_param = model.module.visumodel.parameters()\n",
    "    text_param = model.module.textmodel.parameters()\n",
    "    rest_param = [param for param in model.parameters() if ((param not in visu_param) and (param not in text_param))]\n",
    "    visu_param = list(model.module.visumodel.parameters())\n",
    "    text_param = list(model.module.textmodel.parameters())\n",
    "    sum_visu = sum([param.nelement() for param in visu_param])\n",
    "    sum_text = sum([param.nelement() for param in text_param])\n",
    "    sum_fusion = sum([param.nelement() for param in rest_param])\n",
    "    print('visu, text, fusion module parameters:', sum_visu, sum_text, sum_fusion)\n",
    "else:\n",
    "    visu_param = model.module.visumodel.parameters()\n",
    "    rest_param = [param for param in model.parameters() if param not in visu_param]\n",
    "    visu_param = list(model.module.visumodel.parameters())\n",
    "    sum_visu = sum([param.nelement() for param in visu_param])\n",
    "    sum_text = sum([param.nelement() for param in model.module.textmodel.parameters()])\n",
    "    sum_fusion = sum([param.nelement() for param in rest_param]) - sum_text\n",
    "    print('visu, text, fusion module parameters:', sum_visu, sum_text, sum_fusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build optimizer\n",
    "if args.tunebert:\n",
    "    optimizer = torch.optim.AdamW([{'params': rest_param},\n",
    "            {'params': visu_param, 'lr': args.lr/10.},\n",
    "            {'params': text_param, 'lr': args.lr/10.}], lr=args.lr, weight_decay=0.0001)\n",
    "else:\n",
    "    optimizer = torch.optim.AdamW([{'params': rest_param},\n",
    "            {'params': visu_param}],lr=args.lr, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accu = -float('Inf')\n",
    "for epoch in range(args.nb_epoch):\n",
    "    adjust_learning_rate(args, optimizer, epoch)\n",
    "    \n",
    "    train_epoch(train_loader, model, optimizer, epoch, args)\n",
    "    accu_new = validate_epoch(val_loader, model, args)\n",
    "    ## remember best accu and save checkpoint\n",
    "    is_best = accu_new >= best_accu\n",
    "    best_accu = max(accu_new, best_accu)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_loss': accu_new,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best, args, filename=args.savename)\n",
    "print('\\nBest Accu: %f\\n'%best_accu)\n",
    "logging.info('\\nBest Accu: %f\\n'%best_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
